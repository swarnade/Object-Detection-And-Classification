{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "182248f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2                        #IMPORTING THE CV2 MODULE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c83d4c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loads = cv2.dnn.readNet('yolov4-tiny.weights', 'yolov4-tiny.cfg')    #IMPORTING THE DEEP NEURAL NETWORK(dnn) MODEL\n",
    "used_model = cv2.dnn_DetectionModel(loads)                      \n",
    "used_model.setInputParams(size=(320, 320), scale=1/255)              #SETTING THE INPUT PARAMETERS AND DIMENSIONS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4084f40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=[]                                                             #CONTAINS THE NAMES OF DETECTABLE OBJECTS\n",
    "with open(\"classes.txt\", \"r\") as labels_used:                         \n",
    "    for objects in labels_used.readlines():                           #ARRANGING THEM INTO AN ARRAY\n",
    "        objects = objects.strip()\n",
    "        labels.append(objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fd5de13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_video = cv2.VideoCapture(0)\n",
    "live_video.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)                        #ENSURING THAT HD RESOLUTION OF AN INPUT VIDEO IS ACCPETED    \n",
    "live_video.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0350ef4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    data, frames =live_video.read()\n",
    "    (ids, score, bboxes) = used_model.detect(frames)\n",
    "    for ids, score, bboxes in zip(ids, score, bboxes):\n",
    "        (x, y, w, h) =bboxes\n",
    "        objects = labels[ids]                                                                  #THIS PART CONTAINS THE PART OF\n",
    "        cv2.putText(frames, objects, (x,y-5), cv2.FONT_HERSHEY_TRIPLEX, 1, (200,0,50), 2)      #CODE WHERE A RECTANGLE IS FORMED\n",
    "        cv2.rectangle(frames, (x,y), (x+w,y+h), (200,0,50), 2)                                 #AROUND THE DETECTED OBJECT\n",
    "\n",
    "    cv2.imshow(\"Frame\", frames)                                                                #LOADING THE WEBCAM READY FOR INPUT\n",
    "    cv2.waitKey(1)                                                                             #WAIT TIME BETWEEN EACH FRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f3f19a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86b21bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b96a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
